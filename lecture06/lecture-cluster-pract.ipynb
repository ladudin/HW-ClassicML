{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <td> <center><img src=\"images/header1.png\" width=400></center> </td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "<h1><center>Основы машинного обучения</center></h1>\n",
    "<hr>\n",
    "<h2><center>Методы обучения без учителя: Кластеризация (практика)</center></h2>\n",
    "<h3><center>Ефимов Владислав</center></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-10T15:52:28.591307Z",
     "start_time": "2021-11-10T15:52:27.798700Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-10T15:52:28.785947Z",
     "start_time": "2021-11-10T15:52:28.592370Z"
    },
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vald_\\AppData\\Local\\Temp\\ipykernel_18920\\3813181654.py:5: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.\n",
      "  plt.style.use('seaborn-talk')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('seaborn-talk')\n",
    "plt.rcParams['figure.figsize'] = (12,8)\n",
    "\n",
    "# Для кириллицы на графиках\n",
    "font = {'family': 'Verdana',\n",
    "        'weight': 'normal'}\n",
    "plt.rc('font', **font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment if you are using colab\n",
    "# !mkdir ./data\n",
    "# !wget https://raw.githubusercontent.com/vadim0912/ML2023/main/lecture06/data/diet.csv -O ./data/diet.csv\n",
    "# !wget https://raw.githubusercontent.com/vadim0912/ML2023/main/lecture06/data/snsdata.csv -O ./data/snsdata.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Применение K-means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузите [данные](https://github.com/brenden17/sklearnlab/blob/master/facebook/snsdata.csv) в которых содержится описание интересов профилей учеников старшей школы США."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-10T15:52:50.089970Z",
     "start_time": "2021-11-10T15:52:49.984164Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gradyear</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>friends</th>\n",
       "      <th>basketball</th>\n",
       "      <th>football</th>\n",
       "      <th>soccer</th>\n",
       "      <th>softball</th>\n",
       "      <th>volleyball</th>\n",
       "      <th>swimming</th>\n",
       "      <th>...</th>\n",
       "      <th>blonde</th>\n",
       "      <th>mall</th>\n",
       "      <th>shopping</th>\n",
       "      <th>clothes</th>\n",
       "      <th>hollister</th>\n",
       "      <th>abercrombie</th>\n",
       "      <th>die</th>\n",
       "      <th>death</th>\n",
       "      <th>drunk</th>\n",
       "      <th>drugs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006</td>\n",
       "      <td>M</td>\n",
       "      <td>18.982</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006</td>\n",
       "      <td>F</td>\n",
       "      <td>18.801</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006</td>\n",
       "      <td>M</td>\n",
       "      <td>18.335</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006</td>\n",
       "      <td>F</td>\n",
       "      <td>18.875</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.995</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   gradyear gender     age  friends  basketball  football  soccer  softball  \\\n",
       "0      2006      M  18.982        7           0         0       0         0   \n",
       "1      2006      F  18.801        0           0         1       0         0   \n",
       "2      2006      M  18.335       69           0         1       0         0   \n",
       "3      2006      F  18.875        0           0         0       0         0   \n",
       "4      2006    NaN  18.995       10           0         0       0         0   \n",
       "\n",
       "   volleyball  swimming  ...  blonde  mall  shopping  clothes  hollister  \\\n",
       "0           0         0  ...       0     0         0        0          0   \n",
       "1           0         0  ...       0     1         0        0          0   \n",
       "2           0         0  ...       0     0         0        0          0   \n",
       "3           0         0  ...       0     0         0        0          0   \n",
       "4           0         0  ...       0     0         2        0          0   \n",
       "\n",
       "   abercrombie  die  death  drunk  drugs  \n",
       "0            0    0      0      0      0  \n",
       "1            0    0      0      0      0  \n",
       "2            0    0      1      0      0  \n",
       "3            0    0      0      0      0  \n",
       "4            0    0      0      1      1  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sns = pd.read_csv('data/snsdata.csv', sep=',')\n",
    "df_sns.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные устроены так: \n",
    "* Год выпуска\n",
    "* Пол\n",
    "* Возраст\n",
    "* Количество друзей\n",
    "* 36 ключевых слов, которые встречаются в профилe facebook (интересы, сообщества, встречи)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-10T16:11:44.042982Z",
     "start_time": "2021-11-10T16:11:44.034501Z"
    }
   },
   "source": [
    "#### Задание\n",
    "\n",
    "* Удалите все признаки кроме 36 ключевых слов.\n",
    "* Нормализуйте данные - из каждого столбца вычтите его среднее значение и поделите на стандартное отклонение.\n",
    "* Используйте метод k-means чтобы выделить 9 кластеров\n",
    "* Попробуйте проинтерпретировать каждый кластер проанализировав полученные центройды (Некоторые кластеры могут быть очень большие и очень маленькие - плохо интерпретируются)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Рационы питания в странах"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузите набор данных о пищевом рационе в разных странах мира `diet.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-10T16:29:51.756216Z",
     "start_time": "2021-11-10T16:29:51.751487Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "from sklearn.metrics import silhouette_score, adjusted_rand_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-10T16:29:51.902995Z",
     "start_time": "2021-11-10T16:29:51.891256Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/diet.csv', sep=';').iloc[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-10T16:29:52.058587Z",
     "start_time": "2021-11-10T16:29:52.028970Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Countries</th>\n",
       "      <th>Energy (kcal/day)</th>\n",
       "      <th>Protein (g/day)</th>\n",
       "      <th>Fats (g/day)</th>\n",
       "      <th>Carbohydrates (g/day)</th>\n",
       "      <th>Animal Products + (kcal/day)</th>\n",
       "      <th>Animal Fats (kcal/day)</th>\n",
       "      <th>Bovine Meat (kcal/day)</th>\n",
       "      <th>Butter, Ghee (kcal/day)</th>\n",
       "      <th>Cheese (kcal/day)</th>\n",
       "      <th>...</th>\n",
       "      <th>Soyabean Oil (kcal/day)</th>\n",
       "      <th>Starchy Roots (kcal/day)</th>\n",
       "      <th>Sugar &amp; Sweeteners (kcal/day)</th>\n",
       "      <th>Sugar (Raw Equivalent) (kcal/day)</th>\n",
       "      <th>Sugar, Raw Equivalent (kcal/day)</th>\n",
       "      <th>Sugar, Refined Equiv (kcal/day)</th>\n",
       "      <th>Vegetable Oils (kcal/day)</th>\n",
       "      <th>Vegetables (kcal/day)</th>\n",
       "      <th>Wheat (kcal/day)</th>\n",
       "      <th>Wine (kcal/day)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Albania</td>\n",
       "      <td>2860.0</td>\n",
       "      <td>96</td>\n",
       "      <td>86</td>\n",
       "      <td>425.50</td>\n",
       "      <td>813.0</td>\n",
       "      <td>49</td>\n",
       "      <td>62</td>\n",
       "      <td>11</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>57</td>\n",
       "      <td>193</td>\n",
       "      <td>187</td>\n",
       "      <td>191</td>\n",
       "      <td>187</td>\n",
       "      <td>174</td>\n",
       "      <td>94</td>\n",
       "      <td>1166</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>2980.0</td>\n",
       "      <td>94</td>\n",
       "      <td>100</td>\n",
       "      <td>426.00</td>\n",
       "      <td>823.0</td>\n",
       "      <td>72</td>\n",
       "      <td>342</td>\n",
       "      <td>28</td>\n",
       "      <td>90</td>\n",
       "      <td>...</td>\n",
       "      <td>43</td>\n",
       "      <td>100</td>\n",
       "      <td>406</td>\n",
       "      <td>337</td>\n",
       "      <td>405</td>\n",
       "      <td>337</td>\n",
       "      <td>311</td>\n",
       "      <td>51</td>\n",
       "      <td>914</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Australia</td>\n",
       "      <td>3120.0</td>\n",
       "      <td>107</td>\n",
       "      <td>134</td>\n",
       "      <td>371.50</td>\n",
       "      <td>1033.0</td>\n",
       "      <td>124</td>\n",
       "      <td>142</td>\n",
       "      <td>62</td>\n",
       "      <td>107</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>87</td>\n",
       "      <td>423</td>\n",
       "      <td>407</td>\n",
       "      <td>415</td>\n",
       "      <td>407</td>\n",
       "      <td>435</td>\n",
       "      <td>67</td>\n",
       "      <td>559</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Austria</td>\n",
       "      <td>3740.0</td>\n",
       "      <td>111</td>\n",
       "      <td>162</td>\n",
       "      <td>459.50</td>\n",
       "      <td>1219.0</td>\n",
       "      <td>320</td>\n",
       "      <td>59</td>\n",
       "      <td>102</td>\n",
       "      <td>193</td>\n",
       "      <td>...</td>\n",
       "      <td>89</td>\n",
       "      <td>113</td>\n",
       "      <td>437</td>\n",
       "      <td>404</td>\n",
       "      <td>424</td>\n",
       "      <td>404</td>\n",
       "      <td>442</td>\n",
       "      <td>61</td>\n",
       "      <td>617</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>2200.0</td>\n",
       "      <td>48</td>\n",
       "      <td>25</td>\n",
       "      <td>445.75</td>\n",
       "      <td>65.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>48</td>\n",
       "      <td>42</td>\n",
       "      <td>59</td>\n",
       "      <td>29</td>\n",
       "      <td>59</td>\n",
       "      <td>29</td>\n",
       "      <td>131</td>\n",
       "      <td>10</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Countries  Energy (kcal/day)  Protein (g/day)  Fats (g/day)  \\\n",
       "0     Albania             2860.0               96            86   \n",
       "1   Argentina             2980.0               94           100   \n",
       "2   Australia             3120.0              107           134   \n",
       "3     Austria             3740.0              111           162   \n",
       "4  Bangladesh             2200.0               48            25   \n",
       "\n",
       "   Carbohydrates (g/day)  Animal Products + (kcal/day)  \\\n",
       "0                 425.50                         813.0   \n",
       "1                 426.00                         823.0   \n",
       "2                 371.50                        1033.0   \n",
       "3                 459.50                        1219.0   \n",
       "4                 445.75                          65.0   \n",
       "\n",
       "   Animal Fats (kcal/day)  Bovine Meat (kcal/day)  Butter, Ghee (kcal/day)  \\\n",
       "0                      49                      62                       11   \n",
       "1                      72                     342                       28   \n",
       "2                     124                     142                       62   \n",
       "3                     320                      59                      102   \n",
       "4                       5                       5                        3   \n",
       "\n",
       "   Cheese (kcal/day)  ...  Soyabean Oil (kcal/day)  Starchy Roots (kcal/day)  \\\n",
       "0                 50  ...                        2                        57   \n",
       "1                 90  ...                       43                       100   \n",
       "2                107  ...                       17                        87   \n",
       "3                193  ...                       89                       113   \n",
       "4                  0  ...                       48                        42   \n",
       "\n",
       "   Sugar & Sweeteners (kcal/day)  Sugar (Raw Equivalent) (kcal/day)  \\\n",
       "0                            193                                187   \n",
       "1                            406                                337   \n",
       "2                            423                                407   \n",
       "3                            437                                404   \n",
       "4                             59                                 29   \n",
       "\n",
       "   Sugar, Raw Equivalent (kcal/day)  Sugar, Refined Equiv (kcal/day)  \\\n",
       "0                               191                              187   \n",
       "1                               405                              337   \n",
       "2                               415                              407   \n",
       "3                               424                              404   \n",
       "4                                59                               29   \n",
       "\n",
       "   Vegetable Oils (kcal/day)  Vegetables (kcal/day)  Wheat (kcal/day)  \\\n",
       "0                        174                     94              1166   \n",
       "1                        311                     51               914   \n",
       "2                        435                     67               559   \n",
       "3                        442                     61               617   \n",
       "4                        131                     10               180   \n",
       "\n",
       "   Wine (kcal/day)  \n",
       "0                6  \n",
       "1               59  \n",
       "2               39  \n",
       "3               55  \n",
       "4                0  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-10T16:30:50.317579Z",
     "start_time": "2021-11-10T16:30:50.314290Z"
    }
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-10T16:31:11.833395Z",
     "start_time": "2021-11-10T16:31:11.819102Z"
    }
   },
   "outputs": [],
   "source": [
    "X = df.iloc[:, 1:]\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. Отнормируйте данные с помощью `RobustScaler` или `StandardScaler`\n",
    "2. Используйте метод K-средних. Выберите число кластеров с помощью критерия силуэта\n",
    "3. Найдите выборосы и проинтерпретируйте кластеры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оценка `epsilon` для DBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "То что нам не нужно определять количество выходных кластеров в DBSCAN - это конечно хорошо, но как определить `min_pts` и `epsilon`?) Есть одна методика"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем считать, что MinPts нам дан свыше (например MinPts = 2). Воспользуемся следующим способом оценки:\n",
    "\n",
    "* Нормализуем признаки, например с помощью `RobustScaler` или `StandartScaler`\n",
    "* Расчитаем расстояние до k=MinPts ближайшего соседа каждой точки (класс `NearestNeighbors` и метод `kneighbors`)\n",
    "* Отсортируем полученный массив и выведите его на график\n",
    "* По графику будет примерно понятно, сколько точек уйдет в шум, а сколько попадет в полноценный кластер"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-10T16:34:38.563167Z",
     "start_time": "2021-11-10T16:34:38.558867Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00321914, -0.06351547, -0.10782048, ...,  0.81434012,\n",
       "         1.64193249, -0.16778847],\n",
       "       [ 0.20415642, -0.06970157,  0.25378359, ..., -0.25354278,\n",
       "         0.92710804,  0.1683785 ],\n",
       "       [ 0.44609459, -0.02949189,  1.1319649 , ...,  0.143809  ,\n",
       "        -0.07988671,  0.04152304],\n",
       "       ...,\n",
       "       [ 0.99909611, -0.03877105,  1.23528035, ...,  0.16864349,\n",
       "         0.52431014,  0.00980917],\n",
       "       [ 1.56937892, -0.00784053,  1.70019987, ...,  0.39215386,\n",
       "         0.04492391, -0.12338906],\n",
       "       [-1.02281569, -0.15321399, -0.67605545, ...,  0.01963657,\n",
       "         1.89439033, -0.18681679]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задача про кластеризацию текстов (ДЗ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Рассмотрим коллекцию новостных сообщений за первую половину 2017 года. Про каждое новостное сообщение известны:\n",
    "* его заголовок и текст\n",
    "* дата его публикации\n",
    "* событие, о котором это новостное сообщение написано \n",
    "* его рубрика "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/news.csv', encoding='utf8')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, 'class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем кластеризовать документы (каким-либо методом) и сравним полученное разбиение с данными рубликами с помощью ARI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Стандартная предобработка текстов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Оставляем только кириллические символы\n",
    "regex = re.compile(u\"[А-Яа-я]+\")\n",
    "\n",
    "def words_only(text, regex=regex):\n",
    "    return \" \".join(regex.findall(text))\n",
    "\n",
    "\n",
    "df.text = df.text.str.lower()\n",
    "df.loc[:, 'text'] = df.text.apply(words_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Удаляем стоп-слова\n",
    "mystopwords = stopwords.words('russian') + ['это', 'наш' , 'тыс', 'млн', 'млрд', u'также',  'т', 'д', '-', '-']\n",
    "\n",
    "def  remove_stopwords(text, mystopwords = mystopwords):\n",
    "    try:\n",
    "        return u\" \".join([token for token in text.split() if not token in mystopwords])\n",
    "    except:\n",
    "        return u\"\"\n",
    "    \n",
    "df.text = df.text.apply(remove_stopwords)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "from pymystem3 import Mystem\n",
    "\n",
    "\n",
    "# нормализуем текст\n",
    "m = Mystem()\n",
    "def lemmatize(text, mystem=m):\n",
    "    try:\n",
    "        return \"\".join(m.lemmatize(text)).strip()  \n",
    "    except:\n",
    "        return \" \"\n",
    "\n",
    "df.text = df.text.apply(lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "mystoplemmas = [u'который', u'прошлый', u'сей', u'свой', u'наш', u'мочь']\n",
    "\n",
    "# Еще кое-что удаляем\n",
    "def  remove_stoplemmas(text, mystoplemmas = mystoplemmas):\n",
    "    try:\n",
    "        return \" \".join([token for token in text.split() if not token in mystoplemmas])\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "df.text = df.text.apply(remove_stoplemmas)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.text[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вычисление сходства"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью `TfidfVectorizer` и `pairwise_distances` расчитайте косинусное расстояние между всеми парами документов к корпусе\n",
    "\n",
    "Запишите результат в переменную `S`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import pairwise_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer()\n",
    "texts = df.text.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,10))\n",
    "sns.heatmap(data=S, cmap = 'Spectral').set(xticklabels=[],yticklabels=[])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вы должны пронаблюдать, что между некоторыми текстами есть довольно выскокое сходство по содержанию слов. \n",
    "\n",
    "Попробуем их кластеризовать"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DBSCAN\n",
    "* Воспользуйтесь методикой оценки параметров для алгоритма DBSCAN. Используйте косинусную меру близости\n",
    "* Выделите кластеры. Для каждого кластера (кроме -1, если он будет) выведите несколько текстов и умозрительно определите его тематику\n",
    "* Оцените сходство с изначальными рубриками визуально (с помощью матрицы перемешивания) и с помощью ARI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_rand_score(true_label, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.crosstab(df.loc[:, 'class'], labels)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "livereveal": {
   "theme": "serif",
   "transition": "concave",
   "width": "1024px"
  },
  "nav_menu": {},
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "105px",
    "width": "253px"
   },
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "toc_position": {
   "height": "32px",
   "left": "9px",
   "right": "1379px",
   "top": "33px",
   "width": "212px"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
